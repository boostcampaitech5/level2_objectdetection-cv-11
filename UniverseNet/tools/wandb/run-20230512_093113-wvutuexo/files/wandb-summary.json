{"train/stage0_loss_cls": 1.562912495136261, "train/stage0_pos_acc": 29.07946029663086, "train/stage0_loss_bbox": 1.2561831593513488, "train/stage0_loss_iou": 1.2705428946018218, "train/stage1_loss_cls": 1.5262692785263061, "train/stage1_pos_acc": 26.774676361083984, "train/stage1_loss_bbox": 1.2472838640213013, "train/stage1_loss_iou": 1.2895105624198913, "train/stage2_loss_cls": 1.4742433476448058, "train/stage2_pos_acc": 27.152495250701904, "train/stage2_loss_bbox": 1.2327425253391266, "train/stage2_loss_iou": 1.2767817294597625, "train/stage3_loss_cls": 1.4076462054252625, "train/stage3_pos_acc": 26.597185020446776, "train/stage3_loss_bbox": 1.2600799107551575, "train/stage3_loss_iou": 1.3151045632362366, "train/stage4_loss_cls": 1.4052260160446166, "train/stage4_pos_acc": 23.406821098327637, "train/stage4_loss_bbox": 1.296005630493164, "train/stage4_loss_iou": 1.34755140542984, "train/stage5_loss_cls": 1.3991006422042847, "train/stage5_pos_acc": 27.167020292282103, "train/stage5_loss_bbox": 1.4360113906860352, "train/stage5_loss_iou": 1.445286363363266, "train/loss": 24.44848213195801, "train/grad_norm": 379.277255859375, "learning_rate": 1.6037535714285716e-05, "momentum": 0.9, "_timestamp": 1683884550.7947228, "_runtime": 677.5556027889252, "_step": 450, "_wandb": {"runtime": 707}}