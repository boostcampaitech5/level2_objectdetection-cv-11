{"cells":[{"cell_type":"code","execution_count":null,"id":"8425d721","metadata":{"id":"8425d721","scrolled":true},"outputs":[],"source":["!pip install map_boxes==1.0.5\n","!pip install numpy==1.19.0\n","!pip install tqdm==4.65.0\n","!pip install pycocotools==2.0.6"]},{"cell_type":"code","execution_count":1,"id":"b64e3bb0","metadata":{"id":"b64e3bb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Couldn't import fast version of function compute_overlap, will use slow one. Check cython intallation\n"]}],"source":["from map_boxes import mean_average_precision_for_boxes\n","import pandas as pd\n","import numpy as np\n","import json\n","from tqdm import tqdm\n","from pycocotools.coco import COCO"]},{"cell_type":"code","execution_count":2,"id":"83d36147","metadata":{"id":"83d36147"},"outputs":[],"source":["'''\n","    GT_JSON: valid set json file path\n","    현재 예시에서는 train.json을 임의로 valid set으로 사용\n","    PRED_CSV: 위의 valid set을 inference한 submission file\n","'''\n","# GT_JSON = '../../dataset/train.json'\n","GT_JSON = '/opt/ml/dataset/train.json'\n","# PRED_CSV = '../../sample_submission/train_sample.csv'\n","PRED_CSV = '/opt/ml/baseline/level2_objectdetection-cv-11/UniverseNet/work_dirs/gflv2_pvt_v2_b2_fpn_albu_1024_trash/submission_valid.csv'\n","LABEL_NAME = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n","              \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]\n","    \n","# load ground truth\n","with open(GT_JSON, 'r') as outfile:\n","    test_anno = (json.load(outfile))\n","\n","# load prediction\n","pred_df = pd.read_csv(PRED_CSV)"]},{"cell_type":"code","execution_count":3,"id":"9afc18a0","metadata":{"id":"9afc18a0"},"outputs":[{"name":"stderr","output_type":"stream","text":["4883it [00:01, 2626.93it/s]\n"]}],"source":["'''\n","[\n","    [file_name label_index confidence_score x_min x_max y_min y_max], \n","    [file_name label_index confidence_score x_min x_max y_min y_max],\n","    ,,,\n","    [file_name label_index confidence_score x_min x_max y_min y_max]\n","]\n","\n","이는 아래의 mean_average_precision_for_boxes 함수에 들어갈 양식입니다.\n","new_pred가 위와 같은 format을 갖도록, submission.csv를 가공해봅시다.\n","'''\n","    \n","new_pred = []\n","\n","file_names = pred_df['image_id'].values.tolist()\n","bboxes = pred_df['PredictionString'].values.tolist()\n","    \n","'''\n","create new_pred\n","'''\n","\n","# check variable type\n","for i, bbox in enumerate(bboxes):\n","    if isinstance(bbox, float):\n","        print(f'{file_names[i]} empty box')\n","\n","for file_name, bbox in tqdm(zip(file_names, bboxes)):\n","    boxes = np.array(str(bbox).strip().split(' '))\n","\n","    # boxes - class ID confidence score xmin ymin xmax ymax\n","    if len(boxes) % 6 == 0:\n","        boxes = boxes.reshape(-1, 6)\n","    elif isinstance(bbox, float):\n","        print(f'{file_name} empty box')\n","        continue\n","    else:\n","        raise Exception('error', 'invalid box count')\n","    for box in boxes:\n","        new_pred.append([file_name, box[0], box[1], float(box[2]), float(box[4]), float(box[3]), float(box[5])])"]},{"cell_type":"code","execution_count":4,"id":"1804b52e","metadata":{"id":"1804b52e"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading annotations into memory...\n","Done (t=0.20s)\n","creating index...\n","index created!\n"]}],"source":["'''\n","[\n","    [file_name 1, label_index, x_min, x_max, y_min, y_max], \n","    [file_name 2, label_index, x_min, x_max, y_min, y_max],\n","    ,,,\n","    [file_name , label_index, x_min, x_max, y_min, y_max]\n","]\n","\n","이는 아래의 mean_average_precision_for_boxes 함수에 들어갈 양식입니다.\n","gt가 위와 같은 format을 갖도록, COCO API를 활용하여 가공해봅시다.\n","참고: https://github.com/cocodataset/cocoapi\n","'''\n","    \n","gt = []\n","\n","   \n","'''\n","coco.getImgIds(): return image id list\n","    \n","coco.loadImgs(image_id): return image_info\n","    \n","image_info['file_name']: return file name\n","   \n","coco.getAnnIds(imgIds=image_info['id']): return annotation id\n","    \n","coco.loadAnns(ann_ids): return annotation information list (annotation_info_list)\n","    \n","annotation_info_list[i]['bbox']: return i'th annotation [x_min, y_min, w, h]\n","    \n","annotation_info_list[i]['category_id']: return i'th annotation category\n","    \n","'''\n","coco = COCO(GT_JSON)\n","\n","'''\n","create gt\n",": image id 별로 GT 값 추가\n","'''\n","for image_id in coco.getImgIds():\n","        \n","    image_info = coco.loadImgs(image_id)[0]\n","    annotation_id = coco.getAnnIds(imgIds=image_info['id'])\n","    annotation_info_list = coco.loadAnns(annotation_id)\n","        \n","    file_name = image_info['file_name']\n","        \n","    for annotation in annotation_info_list:\n","        gt.append([file_name, annotation['category_id'],\n","                   float(annotation['bbox'][0]),\n","                   float(annotation['bbox'][0]) + float(annotation['bbox'][2]),\n","                   float(annotation['bbox'][1]),\n","                   (float(annotation['bbox'][1]) + float(annotation['bbox'][3]))])"]},{"cell_type":"code","execution_count":5,"id":"83194763","metadata":{"id":"83194763"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of files in annotations: 4883\n","Number of files in predictions: 4883\n","Unique classes: 10\n","Detections length: 4883\n","Annotations length: 4883\n","0                              | 0.543839 |    3966\n","1                              | 0.670299 |    6352\n","2                              | 0.782903 |     897\n","3                              | 0.711771 |     936\n","4                              | 0.823532 |     982\n","5                              | 0.677763 |    2943\n","6                              | 0.746696 |    1263\n","7                              | 0.833467 |    5178\n","8                              | 0.939261 |     159\n","9                              | 0.804582 |     468\n","mAP: 0.753411\n","0.7534112969285742\n"]}],"source":["'''\n","calculate mAP\n","'''\n","\n","mean_ap, average_precisions = mean_average_precision_for_boxes(gt, new_pred, iou_threshold=0.5)\n","\n","print(mean_ap)"]},{"cell_type":"code","execution_count":6,"id":"55eafe8a","metadata":{"id":"55eafe8a"},"outputs":[{"data":{"text/plain":["'\\n이번 미션에서는 train.json을 이용했지만, 실제 컴피티션에서는 validation set에 대한 모델의 성능을 측정, 트래킹하는 것이 중요합니다.\\nvalidation.json을 만들어, mAP를 계산, 모델의 성능을 측정해봅시다.\\n\\n또한, 심화 미션은 라이브러리를 이용하지 않고, mean_average_precision_for_boxes 함수를 구현하는 것입니다.\\n도전해볼까요?\\n'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","이번 미션에서는 train.json을 이용했지만, 실제 컴피티션에서는 validation set에 대한 모델의 성능을 측정, 트래킹하는 것이 중요합니다.\n","validation.json을 만들어, mAP를 계산, 모델의 성능을 측정해봅시다.\n","\n","또한, 심화 미션은 라이브러리를 이용하지 않고, mean_average_precision_for_boxes 함수를 구현하는 것입니다.\n","도전해볼까요?\n","'''"]},{"cell_type":"markdown","id":"3ab46a38","metadata":{"id":"3ab46a38"},"source":["###**콘텐츠 라이선스**\n","\n","<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n"]},{"cell_type":"markdown","id":"e15eca27","metadata":{},"source":[]},{"cell_type":"markdown","id":"4c788739","metadata":{},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"detection","language":"python","name":"detection"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":5}
